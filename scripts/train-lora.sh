#!/bin/bash
#
# Train LoRA Adapter for Anomaly Analyzer
#
# Prerequisites:
# - Python 3.10+
# - CUDA toolkit (for GPU training)
# - pip install axolotl
#
# Usage: ./scripts/train-lora.sh

set -e

echo "=== Anomaly Analyzer LoRA Training ==="
echo ""

# Check for training data
if [ ! -f "data/training-examples.json" ] && [ ! -f "data/training-data.jsonl" ]; then
    echo "âŒ No training data found!"
    echo ""
    echo "Export training data first:"
    echo "  curl http://localhost:5000/api/monitor/training/export > data/training-data.jsonl"
    exit 1
fi

# Convert training data
echo "ðŸ“¦ Converting training data to Axolotl format..."
node scripts/convert-training-data.js

# Check example count
EXAMPLES=$(wc -l < data/training-data-axolotl.jsonl)
echo "   Found $EXAMPLES training examples"

if [ "$EXAMPLES" -lt 50 ]; then
    echo "âš ï¸  Warning: Less than 50 examples. Consider collecting more for better results."
    read -p "Continue anyway? (y/n) " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        exit 1
    fi
fi

# Check for GPU
if command -v nvidia-smi &> /dev/null; then
    echo "ðŸ–¥ï¸  GPU detected:"
    nvidia-smi --query-gpu=name,memory.total --format=csv,noheader
else
    echo "âš ï¸  No GPU detected. Training will be slow on CPU."
fi

echo ""
echo "ðŸš€ Starting LoRA training..."
echo "   This may take 30-60 minutes on a consumer GPU."
echo ""

# Run training
if command -v accelerate &> /dev/null; then
    accelerate launch -m axolotl.cli.train axolotl-config.yaml
else
    python -m axolotl.cli.train axolotl-config.yaml
fi

echo ""
echo "âœ… Training complete!"
echo ""
echo "Next steps:"
echo "1. Merge LoRA: python -m axolotl.cli.merge_lora axolotl-config.yaml"
echo "2. Convert to GGUF for Ollama"
echo "3. See docs/FINE-TUNING.md for full instructions"
