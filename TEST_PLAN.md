# OpenTelemetry Context Propagation PoC - Test Plan

## Test Overview

This comprehensive test plan validates the OpenTelemetry distributed tracing demonstration across all system components, ensuring authentic instrumentation and proper context propagation in enterprise scenarios.

## Test Environment Setup

### Prerequisites
- Node.js 18+ with npm
- curl for API testing
- Browser with developer tools
- Network access to localhost:5000

### Verification Commands
```bash
# Verify server is running
curl http://localhost:5000/api/traces

# Check OpenTelemetry instrumentation
curl -X POST http://localhost:5000/api/payments \
  -H "Content-Type: application/json" \
  -d '{"amount": 1000, "currency": "USD", "recipient": "test@example.com"}'
```

## Test Categories

### 1. Baseline Functionality Tests

#### Test 1.1: Server Health Check
**Objective**: Verify all services are operational
**Steps**:
1. Navigate to `http://localhost:5000`
2. Verify React frontend loads successfully
3. Check console for errors
4. Confirm payment form is visible

**Expected Results**:
- Frontend loads without errors
- Payment form accepts input
- No console errors or network failures

#### Test 1.2: API Endpoints
**Objective**: Validate all API endpoints respond correctly
**Steps**:
```bash
# Test payments endpoint
curl http://localhost:5000/api/payments

# Test traces endpoint  
curl http://localhost:5000/api/traces

# Test clear endpoint
curl -X DELETE http://localhost:5000/api/clear
```

**Expected Results**:
- `/api/payments` returns payment array
- `/api/traces` returns traces array
- `/api/clear` returns success confirmation

### 2. Context Propagation Tests

#### Test 2.1: Client Headers Disabled (Kong Context Injection)
**Objective**: Verify Kong Gateway injects context for non-instrumented systems
**Steps**:
1. Submit payment via frontend with client headers toggle OFF
2. Capture trace ID from response
3. Verify trace contains Kong Context Injection span
4. Confirm trace ID matches Kong-generated value

**Command**:
```bash
curl -X POST http://localhost:5000/api/payments \
  -H "Content-Type: application/json" \
  -d '{"amount": 25000, "currency": "USD", "recipient": "kong-injection@test.com"}'
```

**Expected Results**:
- Response contains Kong-generated trace ID
- Trace includes "Kong Context Injection" span
- Span attributes show `context.injection: true`
- New trace ID generated by Kong Gateway

#### Test 2.2: Client Headers Enabled (Trace Continuation)
**Objective**: Verify Kong Gateway continues existing trace context
**Steps**:
1. Submit payment with explicit trace headers
2. Verify response uses provided trace ID
3. Confirm Kong span shows "Kong Gateway Proxy" operation
4. Check trace continuity maintained

**Command**:
```bash
curl -X POST http://localhost:5000/api/payments \
  -H "Content-Type: application/json" \
  -H "x-trace-id: client-trace-12345" \
  -H "x-span-id: client-span-67890" \
  -d '{"amount": 30000, "currency": "EUR", "recipient": "client-trace@test.com"}'
```

**Expected Results**:
- Response trace ID matches `client-trace-12345`
- Kong span shows "Kong Gateway Proxy" operation
- Span attributes show `context.injection: false`
- Client-provided context preserved

#### Test 2.3: Context Propagation Comparison
**Objective**: Demonstrate difference between injection and continuation
**Steps**:
1. Execute Test 2.1 and record trace ID
2. Execute Test 2.2 and record trace ID
3. Compare trace structures and timing
4. Verify different Kong span operation names

**Expected Results**:
- Different trace IDs between tests
- Test 2.1: "Kong Context Injection" span
- Test 2.2: "Kong Gateway Proxy" span
- Both maintain proper parent-child relationships

### 3. Distributed Tracing Tests

#### Test 3.1: Complete Trace Flow Validation
**Objective**: Verify end-to-end distributed tracing across all components
**Steps**:
1. Submit payment through any method
2. Retrieve trace data from `/api/traces`
3. Verify all expected spans are present
4. Validate span hierarchy and timing

**Expected Span Structure**:
```
ROOT: POST /api/payments (HTTP auto-instrumentation)
├── Kong Gateway Span (Context Injection or Proxy)
└── Solace Queue Publish (Message broker operation)
```

**Validation Criteria**:
- 3 spans minimum per trace
- Proper parent-child relationships
- Realistic timing (HTTP > Kong > Solace)
- Success status on all spans

#### Test 3.2: Solace Queue Integration
**Objective**: Validate message broker trace correlation
**Steps**:
1. Submit payment with identifiable data
2. Locate Solace Queue Publish span
3. Verify messaging attributes are present
4. Check queue depth and payload size metrics

**Expected Attributes**:
- `messaging.system: "solace"`
- `messaging.destination: "payment-queue"`
- `messaging.operation: "publish"`
- `messaging.message_payload_size: <bytes>`
- `trace.correlation_id: <trace-id>`

#### Test 3.3: Asynchronous Processing
**Objective**: Verify background processing maintains trace correlation
**Steps**:
1. Submit high-value payment (triggers processing)
2. Monitor queue processing in real-time
3. Verify trace correlation maintained
4. Check consumer span creation

**Expected Results**:
- Queue message processed asynchronously
- Consumer spans created with correct correlation
- Original trace ID maintained throughout flow
- Processing timing captured accurately

### 4. Performance and Timing Tests

#### Test 4.1: Latency Impact Measurement
**Objective**: Measure OpenTelemetry overhead on request processing
**Steps**:
1. Submit 10 payments without tracing (baseline)
2. Submit 10 payments with full tracing enabled
3. Compare average response times
4. Verify overhead is minimal (<5ms)

**Commands**:
```bash
# Baseline timing test
for i in {1..10}; do
  time curl -X POST http://localhost:5000/api/payments \
    -H "Content-Type: application/json" \
    -d "{\"amount\": $((RANDOM * 100)), \"currency\": \"USD\", \"recipient\": \"perf-test-$i@example.com\"}" \
    -s > /dev/null
done
```

**Expected Results**:
- Tracing overhead < 5ms per request
- Kong Gateway latency 3-6ms
- Solace queue latency < 1ms
- Total overhead acceptable for enterprise use

#### Test 4.2: Concurrent Request Handling
**Objective**: Verify trace isolation under concurrent load
**Steps**:
1. Submit 5 payments simultaneously
2. Verify each gets unique trace ID
3. Check no span mixing between traces
4. Confirm all traces complete successfully

**Command**:
```bash
# Concurrent requests
for i in {1..5}; do
  curl -X POST http://localhost:5000/api/payments \
    -H "Content-Type: application/json" \
    -d "{\"amount\": $((i * 1000)), \"currency\": \"USD\", \"recipient\": \"concurrent-$i@test.com\"}" \
    -s &
done
wait
```

**Expected Results**:
- 5 unique trace IDs generated
- No span contamination between traces
- All requests complete within 100ms
- Proper trace isolation maintained

### 5. Error Handling Tests

#### Test 5.1: Invalid Payment Data
**Objective**: Verify error tracing for failed requests
**Steps**:
1. Submit payment with invalid data
2. Verify error status in trace spans
3. Check error attributes are captured
4. Confirm partial trace still created

**Command**:
```bash
curl -X POST http://localhost:5000/api/payments \
  -H "Content-Type: application/json" \
  -d '{"amount": "invalid", "currency": "USD"}'
```

**Expected Results**:
- HTTP span shows error status
- Kong span captures error attributes
- Trace created despite validation failure
- Error details preserved in span metadata

#### Test 5.2: Queue Processing Failures
**Objective**: Test error handling in asynchronous processing
**Steps**:
1. Trigger queue processing error (if applicable)
2. Verify error spans are created
3. Check retry logic maintains trace correlation
4. Confirm error attributes captured

**Expected Results**:
- Error spans show failure status
- Retry attempts maintain trace correlation
- Error messages captured in span attributes
- Queue processing gracefully handles failures

### 6. Integration Tests

#### Test 6.1: Frontend Integration
**Objective**: Verify frontend trace header generation
**Steps**:
1. Enable client headers in frontend
2. Submit payment through UI
3. Verify trace headers sent in request
4. Check trace continuation works correctly

**Expected Results**:
- Frontend generates valid trace headers
- Headers follow W3C Trace Context format
- Backend continues frontend-initiated trace
- UI displays trace information correctly

#### Test 6.2: Browser Developer Tools
**Objective**: Validate trace visibility in browser tools
**Steps**:
1. Open browser developer tools
2. Submit payment through frontend
3. Check Network tab for trace headers
4. Verify no client-side errors

**Expected Results**:
- Trace headers visible in request
- Response includes trace correlation data
- No JavaScript errors in console
- Network requests complete successfully

### 7. Data Validation Tests

#### Test 7.1: Trace Data Accuracy
**Objective**: Verify all trace data is authentic and accurate
**Steps**:
1. Submit test payment with known values
2. Retrieve trace data from API
3. Validate all timing is realistic
4. Check span attributes match actual operations

**Validation Points**:
- HTTP span duration matches request time
- Kong span timing realistic (3-6ms)
- Solace span timing minimal (<1ms)
- All timestamps in correct sequence
- No synthetic or mock data present

#### Test 7.2: Span Relationship Validation
**Objective**: Verify proper parent-child span relationships
**Steps**:
1. Analyze trace hierarchy structure
2. Confirm parent-child relationships correct
3. Verify no orphaned spans
4. Check trace ID consistency across spans

**Expected Structure**:
- HTTP span as root (no parent)
- Kong span child of HTTP span
- Solace span child of HTTP span
- All spans share same trace ID

### 8. Security Tests

#### Test 8.1: Trace Header Injection
**Objective**: Verify system handles malicious trace headers safely
**Steps**:
1. Submit requests with malformed trace headers
2. Verify system handles gracefully
3. Check no security vulnerabilities
4. Confirm trace data remains consistent

**Commands**:
```bash
# Test malformed headers
curl -X POST http://localhost:5000/api/payments \
  -H "x-trace-id: ../../../etc/passwd" \
  -H "x-span-id: <script>alert('xss')</script>" \
  -H "Content-Type: application/json" \
  -d '{"amount": 1000, "currency": "USD", "recipient": "security@test.com"}'
```

**Expected Results**:
- Malformed headers rejected or sanitized
- No security vulnerabilities exploited
- System generates valid trace data
- No unexpected behavior or errors

## Test Execution Schedule

### Phase 1: Basic Functionality (15 minutes)
- Tests 1.1 - 1.2: Server health and API validation

### Phase 2: Core Features (30 minutes)  
- Tests 2.1 - 2.3: Context propagation validation
- Tests 3.1 - 3.3: Distributed tracing verification

### Phase 3: Performance (20 minutes)
- Tests 4.1 - 4.2: Latency and concurrency testing

### Phase 4: Edge Cases (15 minutes)
- Tests 5.1 - 5.2: Error handling validation
- Tests 8.1: Security testing

### Phase 5: Integration (10 minutes)
- Tests 6.1 - 6.2: Frontend and browser integration
- Tests 7.1 - 7.2: Data validation

## Success Criteria

### Must Pass
- All baseline functionality tests (1.x)
- Context propagation tests (2.x)
- Complete distributed tracing (3.1)
- No security vulnerabilities (8.1)

### Should Pass
- Performance within acceptable limits (4.x)
- Error handling graceful (5.x)
- Frontend integration smooth (6.x)
- Data accuracy verified (7.x)

## Test Reporting

### Pass/Fail Criteria
- **PASS**: All expected results achieved
- **FAIL**: Any expected result not met
- **SKIP**: Test not applicable or blocked

### Documentation Requirements
- Record all test results with timestamps
- Capture trace IDs for analysis
- Document any deviations from expected behavior
- Include performance measurements

### Issue Tracking
- Critical: System completely broken
- High: Core functionality impacted  
- Medium: Performance or usability issues
- Low: Minor inconsistencies or improvements

## Automated Testing Integration

### Continuous Testing Commands
```bash
# Quick smoke test
npm test

# Full integration test suite
npm run test:integration

# Performance benchmark
npm run test:performance
```

### CI/CD Integration Points
- Pre-deployment validation
- Performance regression testing
- Security vulnerability scanning
- Trace data integrity verification